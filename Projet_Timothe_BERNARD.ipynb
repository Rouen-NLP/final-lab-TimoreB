{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advertisement/0000136188.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advertisement/0000435350.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advertisement/0000556056.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advertisement/0030048095.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advertisement/0030048989.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Advertisement/0030049569.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Advertisement/03496270.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Advertisement/03567810.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Advertisement/03722789.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Advertisement/04102204.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       img_path          label\n",
       "0  Advertisement/0000136188.jpg  Advertisement\n",
       "1  Advertisement/0000435350.jpg  Advertisement\n",
       "2  Advertisement/0000556056.jpg  Advertisement\n",
       "3  Advertisement/0030048095.jpg  Advertisement\n",
       "4  Advertisement/0030048989.jpg  Advertisement\n",
       "5  Advertisement/0030049569.jpg  Advertisement\n",
       "6    Advertisement/03496270.jpg  Advertisement\n",
       "7    Advertisement/03567810.jpg  Advertisement\n",
       "8    Advertisement/03722789.jpg  Advertisement\n",
       "9    Advertisement/04102204.jpg  Advertisement"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../nlp-labs/tobacco-lab/data/Tobacco3482.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9cdccf9160>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.countplot(data['label'],orient='h')\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = []\n",
    "for root, dirs, files in os.walk(\"./data\", topdown=False):\n",
    "    for name in files:\n",
    "        if \".txt\" in os.path.join(root, name) :\n",
    "            list_files.append(os.path.join(root, name))\n",
    "\n",
    "list_text = []\n",
    "for file in list_files:\n",
    "    file_object = open(file,'r')\n",
    "    list_text.append(file_object.read())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {}\n",
    "for i in range(len(data['img_path'])):\n",
    "    dict_data['../nlp-labs/tobacco-lab/data/'+data['img_path'][i].replace('jpg','txt')] = data['label'][i] \n",
    "X = []\n",
    "y = []\n",
    "for i in dict_data:\n",
    "    file_object = open(i,\"r\")\n",
    "    X.append(file_object.read())\n",
    "    file_object.close()\n",
    "    y.append(dict_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test,y_train,  y_test = train_test_split(X,y, test_size=0.2)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution (Phase de train) :  0.8309386973180076\n",
      "Evalution (Phase de test) :  0.7374461979913917 \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Advertisement       0.77      0.65      0.71        55\n",
      "        Email       0.95      0.95      0.95       110\n",
      "         Form       0.72      0.80      0.76        85\n",
      "       Letter       0.74      0.70      0.72       116\n",
      "         Memo       0.66      0.76      0.70       113\n",
      "         News       0.60      0.81      0.69        36\n",
      "         Note       0.54      0.36      0.43        39\n",
      "       Report       0.57      0.55      0.56        62\n",
      "       Resume       1.00      1.00      1.00        29\n",
      "   Scientific       0.78      0.62      0.69        52\n",
      "\n",
      "    micro avg       0.74      0.74      0.74       697\n",
      "    macro avg       0.73      0.72      0.72       697\n",
      " weighted avg       0.74      0.74      0.73       697\n",
      "\n",
      "[[ 36   0   3   2   5   5   3   1   0   0]\n",
      " [  0 105   0   1   1   0   0   3   0   0]\n",
      " [  3   0  68   3   3   2   5   0   0   1]\n",
      " [  0   1   1  81  16   2   2  12   0   1]\n",
      " [  1   1   4  14  86   3   1   3   0   0]\n",
      " [  2   0   2   0   0  29   0   1   0   2]\n",
      " [  3   4   6   3   7   1  14   0   0   1]\n",
      " [  2   0   3   5   9   5   0  34   0   4]\n",
      " [  0   0   0   0   0   0   0   0  29   0]\n",
      " [  0   0   7   1   4   1   1   6   0  32]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def model_NB_train(X_train,y_train,max_features = 2000):\n",
    "    # On vectorize nos tweets\n",
    "    vectorizer = CountVectorizer(max_features=2000)\n",
    "    vectorizer.fit(X_train)\n",
    "    X_train_counts = vectorizer.transform(X_train)\n",
    "    \n",
    "    # On entraine nos Naives Bayes\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train_counts,y_train)\n",
    "\n",
    "    y_pred_train = model.predict(X_train_counts)\n",
    "   \n",
    "    print(\"Evalution (Phase de train) : \",accuracy_score(y_train,y_pred_train))\n",
    "    return model,vectorizer\n",
    "\n",
    "def model_NB_test(model,vectorizer,X_test,y_test):\n",
    "    \n",
    "    X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "    y_pred_test = model.predict(X_test_counts)\n",
    "    \n",
    "    print(\"Evalution (Phase de test) : \",accuracy_score(y_test,y_pred_test),\"\\n\")\n",
    "    print(classification_report(y_test,y_pred_test))\n",
    "    print(confusion_matrix(y_test,y_pred_test))\n",
    "    return model\n",
    "\n",
    "model,vectorizer = model_NB_train(X_train,y_train)\n",
    "model_NB_test(model,vectorizer,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commentaires \n",
    "\n",
    "Pas de soucis pour retrouver les CVs, Ã§a il y arrive bien. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier(activation='logistic')\n",
    "\n",
    "X_train_counts = vectorizer.transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "model.fit(X_train_counts,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalution (Phase de train) :  0.9966475095785441\n",
      "Evalution (Phase de test) :  0.7546628407460545 \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Advertisement       0.66      0.67      0.67        55\n",
      "        Email       0.95      0.97      0.96       110\n",
      "         Form       0.75      0.82      0.79        85\n",
      "       Letter       0.75      0.72      0.73       116\n",
      "         Memo       0.78      0.81      0.80       113\n",
      "         News       0.73      0.67      0.70        36\n",
      "         Note       0.53      0.64      0.58        39\n",
      "       Report       0.53      0.45      0.49        62\n",
      "       Resume       1.00      1.00      1.00        29\n",
      "   Scientific       0.69      0.60      0.64        52\n",
      "\n",
      "    micro avg       0.75      0.75      0.75       697\n",
      "    macro avg       0.74      0.74      0.73       697\n",
      " weighted avg       0.75      0.75      0.75       697\n",
      "\n",
      "[[ 37   0   3   0   0   2  11   1   0   1]\n",
      " [  1 107   0   0   2   0   0   0   0   0]\n",
      " [  3   0  70   4   1   1   4   0   0   2]\n",
      " [  1   1   3  83  13   1   3   9   0   2]\n",
      " [  1   4   2   9  92   0   1   3   0   1]\n",
      " [  5   0   1   0   1  24   0   4   0   1]\n",
      " [  5   1   5   2   0   0  25   0   0   1]\n",
      " [  2   0   6  10   6   3   1  28   0   6]\n",
      " [  0   0   0   0   0   0   0   0  29   0]\n",
      " [  1   0   3   2   3   2   2   8   0  31]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train_counts)\n",
    "print(\"Evalution (Phase de train) : \",accuracy_score(y_train,y_pred_train))\n",
    "y_pred_test = model.predict(X_test_counts)\n",
    "    \n",
    "print(\"Evalution (Phase de test) : \",accuracy_score(y_test,y_pred_test),\"\\n\")\n",
    "print(classification_report(y_test,y_pred_test))\n",
    "print(confusion_matrix(y_test,y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'mlp']\n",
      "parameters:\n",
      "{'mlp__activation': ('logistic', 'relu'), 'vect__max_df': (0.5, 0.75, 1.0)}\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 420, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 563, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 261, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 261, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 528, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 265, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 230, in _fit\n    **fit_params_steps[name])\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\", line 329, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 614, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 1012, in fit_transform\n    self.fixed_vocabulary_)\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 922, in _count_vocab\n    for feature in analyze(doc):\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 308, in <lambda>\n    tokenize(preprocess(self.decode(doc))), stop_words)\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 256, in <lambda>\n    return lambda x: strip_accents(x.lower())\n  File \"/home/tbernard/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\", line 647, in __getattr__\n    raise AttributeError(attr + \" not found\")\nAttributeError: lower not found\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-17cabdc91524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done in %0.3fs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "# Hyperameters optimization with GridSearchCV = parallel processing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('mlp', MLPClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'mlp__activation': ( 'logistic', 'relu')\n",
    "}\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=2)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_test_counts, y_test)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
